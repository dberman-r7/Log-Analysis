# Change Request: CR-2026-02-12-001

**Status**: APPROVED

**Created**: 2026-02-12 00:00:00 UTC  
**Last Updated**: 2026-02-16 00:00:00 UTC

---

## Basic Information

**Title**: Dedicated Parquet cache per log/time-span with partial-range fetch, multi-parquet analysis, streaming flush, and parquet-derived summaries

**Requestor**: dberman

**Category**: FEATURE (Performance / Reliability / Observability)

**Priority**:
- [ ] P0 - CRITICAL (System down, security breach)
- [ ] P1 - HIGH (Major feature, significant bug)
- [x] P2 - MEDIUM (Minor feature, moderate bug)
- [ ] P3 - LOW (Enhancement, minor issue)

**Urgency**:
- [ ] IMMEDIATE (Within 24 hours)
- [ ] HIGH (Within 1 week)
- [x] NORMAL (Within 2 weeks)
- [ ] LOW (Next sprint/release)

---

## Description

### Problem Statement
Repeated ingestion runs over the same `(log_id, time_window)` re-download data unnecessarily, wasting API quota/time. The current ingestion approach can also hold too much data in memory when processing large windows.

### Proposed Solution
1. Persist downloaded events into a **dedicated local Parquet cache** keyed by `(log key/id, time-window)` and reuse cached data on reruns.
2. Before any API call, compute **cache coverage** for the requested **half-open** interval `[start_time, end_time)`.
3. If coverage is partial, compute **missing subranges** (supports multiple gaps) and fetch **only those** missing ranges.
4. For partial coverage, persist **additional segment datasets/files** for only the missing subranges (no in-place merge/compaction required). Analysis reads from **multiple Parquet segments** for the requested window.
5. Reduce memory usage by processing Log Search results page-by-page and **flushing buffered rows to Parquet** after a configurable threshold (rows and/or bytes), clearing buffers after flush.
6. After processing, emit a **Parquet-derived summary** (row count, columns/types, timestamp min/max, etc.).

### Business Justification
- Faster reruns, lower API usage, reproducible datasets.
- Bounded memory footprint for large windows (reliability).
- Better operator insight via summaries and cache decision logs (observability).

### Alternatives Considered
- In-place merge/compaction of segments: rejected for now due to complexity and write amplification.
- Storing raw pages only: rejected because analysis needs columnar format and schema evolution handling.

---

## Affected Components

**Systems**:
- [ ] Web Application
- [x] API Backend (client integration)
- [ ] Database
- [ ] Message Queue
- [x] Cache Layer (local filesystem)
- [x] External Integrations (Rapid7 APIs)
- [ ] CI/CD Pipeline
- [ ] Infrastructure
- [x] Documentation
- [ ] Other: _______

**Modules/Services**:
- `src/log_ingestion/service.py`
- `src/log_ingestion/cache_index.py`
- `src/log_ingestion/parquet_writer.py`
- `src/log_ingestion/parquet_summary.py`
- `src/log_ingestion/config.py`
- `src/log_ingestion/main.py`

**Files** (Estimated):
- `src/log_ingestion/*` (cache decision + streaming flush + summary output)
- `tests/test_service*.py`, `tests/test_cache_index*.py`, `tests/test_parquet_summary.py`
- `docs/requirements/rtm.md`, `docs/runbooks/log-ingestion-service.md`, (optional) `docs/requirements/slos.md`

---

## Approval Status

**Approval Token Received**: ATP
**Approval Date**: 2026-02-12

---

## Impact Assessment (IA)

### 1) Functional / UX Impact
- **Functional change?** YES
  - New cache layer that can skip/reduce API calls based on coverage.
  - New on-disk artifact layout: multiple segments/parts per `(log_id, time range)`.
  - New/expanded CLI/service output: parquet-derived summary and cache decision events.

### 2) Data / Storage Impact
- Increased data-at-rest footprint (Parquet cache on local filesystem).
- File count can grow due to segment + part files; will require operator guidance and a retention/cleanup section in the runbook.

### 3) Performance / SLO Impact
- Positive: reduced network calls on reruns and partial coverage.
- Positive: **bounded memory** via streaming flush (page-by-page processing with periodic writes).
- Potential negative: many small part files can slow reads; mitigated by configurable flush thresholds and guidance.

### 4) Reliability / Failure-Mode Impact
- New failure modes (must fail loudly):
  - Cache directory not writable / partial writes.
  - Corrupt or unreadable Parquet segments.
  - Index drift (metadata vs filesystem).
  - Off-by-one boundary mistakes in `[start,end)` interval math.
- Mitigations:
  - Strong unit tests for range math and coverage.
  - Structured ERROR logs and abort on read/write failures, unless explicit bypass-cache mode enabled.

### 5) Security / Compliance Impact
- Local persistence of log events increases sensitivity of local storage.
- Must avoid directory traversal and ensure cache paths remain within configured cache root.
- No secrets are written to Parquet or logs.

### 6) Observability Impact
Add structured logs:
- `cache_hit` / `cache_miss` / `cache_partial` with requested window and missing subranges.
- `flush_start` / `flush_complete` with rows/paths.
- `parquet_summary_generated` with key summary fields.
- Explicit ERROR logs on corruption/read/write failures.

### 7) Testing Impact
Add/extend tests:
- Missing-subrange planner correctness including multiple gaps and adjacency.
- Streaming flush behavior (buffer cleared; multiple part files written).
- Multi-parquet dataset reads.
- Parquet summary generation (new test added: `tests/test_parquet_summary.py`).

### 8) Documentation Impact
- RTM: add/update REQ entries + trace links.
- Runbook: cache layout, tuning (flush rows/bytes), retention, troubleshooting.
- (Optional) SLOs: cache hit rate, time-to-first-flush, max memory.

### Rollback Plan
- Set `BYPASS_CACHE=true` to revert to API-only behavior.
- Set very large flush threshold to mimic prior in-memory behavior (temporary workaround).
- Delete cache directory to reset state (operator action).

---

## Technical Design (high level)

### Range semantics
All windows use **half-open** `[start_time, end_time)`.

### Cache key + layout
- Cache root: `LOG_INGESTION_CACHE_DIR`.
- Keyed by `log_id` (or `rapid7_log_key`) and subrange boundaries.
- Store missing subranges as new segment directories; each segment contains `part-00000.parquet` etc.

### Partial coverage fetch algorithm
1. List cached segments for `log_id`.
2. Compute union of cached ranges.
3. Subtract union from requested range to produce **sorted, non-overlapping** missing intervals.
4. Query API for each missing interval and write into corresponding segment directory.
5. Read all intersecting segments for final dataset/summary.

### Streaming flush
- Ingestion processes API results page-by-page.
- Buffer events until `FLUSH_ROWS` (and/or `FLUSH_BYTES`) reached, then write a part file and clear buffer.

---

## Tracking

- **Related Implementation Plan**: `docs/processes/implementation-plans/IP-2026-02-12-001-multi-parquet-cache-and-streaming-flush.md`
- **Related Requirements**: REQ-023, REQ-024, REQ-025, REQ-026, REQ-027, REQ-028, REQ-029
